xs[i,unrealistic.speed.idxs] <- NA
ys[i,unrealistic.speed.idxs] <- NA
xs[i,unrealistic.speed.idxs + 1] <- NA
ys[i,unrealistic.speed.idxs + 1] <- NA
}
#Interpolate through seqs of NAs of length < max.interp
for(i in 1:n.inds){
#data for a single individual
x <- xs[i,]
y <- ys[i,]
#vectors to hold interpolated data
x.interp <- x
y.interp <- y
#get runs of NAs
runs <- rle(is.na(x)) #get runs of NAs
vals <- runs$values
lens <- runs$lengths
idxs <- c(0, cumsum(runs$lengths))
#for each run of NAs, fill in with linearly interp values if length is less than max.interp
for(j in 1:length(vals)){
if(vals[j]==TRUE){
first.idx <- idxs[j]+1
last.idx <- idxs[j+1]
#If not too near the beginning or the end of the sequence...
if((first.idx > 1) & (last.idx < length(x))){
#Get values before and after NA sequence
prev.val.x <- x[first.idx-1]
next.val.x <- x[last.idx + 1]
prev.val.y <- y[first.idx-1]
next.val.y <- y[last.idx +1]
#Fill in with linear interpolation if the NA sequence is short (< 5)
if(lens[j] <= max.interp){
interp.vals.x <- seq(prev.val.x,next.val.x,length.out=lens[j]+2)
interp.vals.y <- seq(prev.val.y,next.val.y,length.out=lens[j]+2)
x.interp[seq(first.idx-1,last.idx+1)] <- interp.vals.x
y.interp[seq(first.idx-1,last.idx+1)] <- interp.vals.y
}
#Otherwise...if less than 5 minutes gap...
if((lens[j] > max.interp) & (lens[j] < max.move.time)){
#Fill in with mean value at start and end if they are close enough ( <= max.move)
dist.moved <- sqrt((next.val.x - prev.val.x)^2 + (next.val.y - prev.val.y)^2)
time.elapsed <- last.idx - first.idx
if(dist.moved < max.move){
mean.x <- mean(c(next.val.x,prev.val.x))
mean.y <- mean(c(next.val.y,prev.val.y))
x.interp[seq(first.idx,last.idx)] <- mean.x
y.interp[seq(first.idx,last.idx)] <- mean.y
}
}
}
}
}
xs[i,] <- x.interp
ys[i,] <- y.interp
}
##--------- STEP 1 of removing extreme  points --
for(i in 1:n.inds){
print('ind:')
print(i)
xi <- xi.new <- xs[i,]
yi <- yi.new <- ys[i,]
non.nas <- which(!is.na(xi))
#get very large or very small values of x and y (outside their normal range)
bigs <- unique(c(which(xi>quantile(xi,max.dist.quantile,na.rm=T)),which(yi>quantile(yi,max.dist.quantile,na.rm=T))))
smalls <- unique(c(which(xi<quantile(xi,min.dist.quantile,na.rm=T)),which(yi<quantile(yi,min.dist.quantile,na.rm=T))))
extremes <- unique(c(bigs,smalls))
#for each extreme value, find the previous and next non-NA data point
#if this previous point is more than 1 km away, just replace the unrealistic location with NA
#otherwise, leave it
for(j in 1:length(extremes)){
t.idx <- extremes[j]
prev.t <- max(non.nas[which(non.nas < t.idx)])
next.t <- min(non.nas[which(non.nas > t.idx)])
dist.prev <- sqrt((xs[i,prev.t]-xs[i,t.idx])^2 + (ys[i,prev.t]-ys[i,t.idx])^2)
dist.next <- sqrt((xs[i,next.t]-xs[i,t.idx])^2 + (ys[i,next.t]-ys[i,t.idx])^2)
if(dist.prev > 1000 & dist.next > 1000){
xi.new[t.idx] <- NA
yi.new[t.idx] <- NA
}
}
xs[i,] <- xi.new
ys[i,] <- yi.new
}
##--------- STEP 2 of removing extreme  points --
#Find and remove super unrealistic locations (>mean + 10*sd for each ind in x or y)
for(i in 1:n.inds){
xi <- xs[i,]
yi <- ys[i,]
extremes.high.x <- which(xi > mean(xi,na.rm=T)+10*sd(xi,na.rm=T))
extremes.low.x <- which(xi < mean(xi,na.rm=T)-10*sd(xi,na.rm=T))
extremes.high.y <- which(yi > mean(yi,na.rm=T)+10*sd(yi,na.rm=T))
extremes.low.y <- which(yi < mean(yi,na.rm=T)-10*sd(yi,na.rm=T))
extremes <- c(extremes.high.x,extremes.high.y,extremes.low.x,extremes.low.y)
if(length(extremes)>0){
xs[i,extremes] <- NA
ys[i,extremes] <- NA
}
}
#Save as RData
save(file=paste0(data_dir, 'presedente_xy_highres_level2.RData'),list=c('xs','ys'))
library(lubridate)
library(dbscan)
#DIRECTORIES AND PARAMETERS
R_inner <- 15
R_outer <- 50
group <- 'galaxy' #subdirectory where the group data is stored
#get directory to group data
groupdir <- paste0(dir,group)
#for Emily:
codedir <- 'C:/Users/egrout/Dropbox/coatithon/coatithon_code/'
groupdir <- "C:/Users/egrout/Dropbox/coatithon/processed/2022/galaxy/"
plot_dir <- 'C:/Users/egrout/Dropbox/coatithon/results/galaxy_results/level1/'
#SOURCE FUNCTIONS
setwd(codedir)
source('coati_function_library.R')
#LOAD DATA
#navigate into directory
setwd(codedir)
#read in events
events <- read.csv(paste0('C:/Users/egrout/Dropbox/coatithon/processed/split_analysis_processed/',group,'_manual_split_merge_clean.csv'), sep=';')
#read in coati ids
setwd(groupdir)
load(file=paste0(group,'_coati_ids.RData'))
#read in timestamp data
load(file=paste0(group,'_xy_highres_level1.RData'))
#read in timestamp data
load(file=paste0(group,'_xy_highres_level2.RData'))
ff_data_50 <- detect_fissions_and_fusions(R_inner = 15, R_outer = 50, xs, ys, ts, coati_ids)
View(ff_data_50)
View(ff_data_50)
gal_events_detected
gal_events_detected <- ff_data_50$events_detected
gal_events_detected
View(gal_events_detected)
gal_events_detected <- ff_data_50$groups_list
gal_events_detected <- ff_data_50$together
View(gal_events_detected)
gal_events_detected
unique(gal_events_detected)
unique(gal_events_detected)
sum(unique(gal_events_detected))
sum(na.omit(unique(gal_events_detected)))
#read in timestamp data
load(file=paste0(group,'_xy_highres_level1.RData'))
ff_data_50 <- detect_fissions_and_fusions(R_inner = 15, R_outer = 50, xs, ys, ts, coati_ids)
bla <- ff_data_50$together
unique(bla)
unique(bla[[1]])
unique(bla[1])
#looking at one event
analyse_ff_event(12, events = ff_data_50$events_detected, xs, ys, ts, max_time = 600)
#animate events
i <- 10
max_time <- 600
step_t <- 5
#change gal to pres if presidente group
ti <- gal_events_detected$tidx[i] - max_time
gal_events_detected <- ff_data_50$events_detected
#change gal to pres if presidente group
ti <- gal_events_detected$tidx[i] - max_time
tf <- gal_events_detected$tidx[i] + max_time
group_A_idxs <- gal_events_detected$group_A_idxs[i][[1]]
group_B_idxs <- gal_events_detected$group_B_idxs[i][[1]]
all_idxs <- 1:nrow(xs)
not_involved_idxs <- setdiff(all_idxs, c(group_A_idxs, group_B_idxs))
event_type <- gal_events_detected$event_type[i]
xmin <- min(xs[,ti:tf],na.rm=T)
xmax <- max(xs[,ti:tf],na.rm=T)
ymin <- min(ys[,ti:tf],na.rm=T)
ymax <- max(ys[,ti:tf],na.rm=T)
tseq <- seq(ti,tf,step_t)
for(t in tseq){
#clear()
if(t >= gal_events_detected$tidx[i]){
points((xmax+xmin)/2,(ymin+ymax)/2,col='orange',cex = 5)
}
plot(NULL, xlim=c(xmin,xmax),ylim=c(ymin,ymax),asp=1,xlab='Easting',ylab='Northing',main = event_type)
if(length(not_involved_idxs)>0){
points(xs[not_involved_idxs,t],ys[not_involved_idxs,t],col='#00000033',pch=19)
}
points(xs[group_A_idxs,t],ys[group_A_idxs,t],pch=19, col = 'red')
points(xs[group_B_idxs,t],ys[group_B_idxs,t],pch=19, col = 'blue')
Sys.sleep(.01)
}
plot(NULL, xlim=c(xmin,xmax),ylim=c(ymin,ymax),asp=1,xlab='Easting',ylab='Northing',main = event_type)
if(length(not_involved_idxs)>0){
points(xs[not_involved_idxs,t],ys[not_involved_idxs,t],col='#00000033',pch=19)
}
points(xs[group_A_idxs,t],ys[group_A_idxs,t],pch=19, col = 'red')
points(xs[group_B_idxs,t],ys[group_B_idxs,t],pch=19, col = 'blue')
#looking at one event
analyse_ff_event(12, events = ff_data_50$events_detected, xs, ys, ts, max_time = 600)
for(t in tseq){
#clear()
if(t >= gal_events_detected$tidx[i]){
points((xmax+xmin)/2,(ymin+ymax)/2,col='orange',cex = 5)
}
plot(NULL, xlim=c(xmin,xmax),ylim=c(ymin,ymax),asp=1,xlab='Easting',ylab='Northing',main = event_type)
if(length(not_involved_idxs)>0){
points(xs[not_involved_idxs,t],ys[not_involved_idxs,t],col='#00000033',pch=19)
}
points(xs[group_A_idxs,t],ys[group_A_idxs,t],pch=19, col = 'red')
points(xs[group_B_idxs,t],ys[group_B_idxs,t],pch=19, col = 'blue')
Sys.sleep(.01)
}
quartz()
tseq <- seq(ti,tf,step_t)
for(t in tseq){
#clear()
if(t >= gal_events_detected$tidx[i]){
points((xmax+xmin)/2,(ymin+ymax)/2,col='orange',cex = 5)
}
plot(NULL, xlim=c(xmin,xmax),ylim=c(ymin,ymax),asp=1,xlab='Easting',ylab='Northing',main = event_type)
if(length(not_involved_idxs)>0){
points(xs[not_involved_idxs,t],ys[not_involved_idxs,t],col='#00000033',pch=19)
}
points(xs[group_A_idxs,t],ys[group_A_idxs,t],pch=19, col = 'red')
points(xs[group_B_idxs,t],ys[group_B_idxs,t],pch=19, col = 'blue')
Sys.sleep(.01)
}
library(lubridate)
library(scales)
#----------PARAMETERS - MODIFY HERE--------------
#which group (galaxy or presedente)
group <- 'galaxy'
#who is using (ari or emily)
user <- 'emily'
#whether to identify splits and merges automatically (if F) or use manually identified events (if T)
use_manual_events <- F
#---PARAMETERS (probably don't modify)---
#events filename - where to get the split/merge events for manually labeled events
events.filename <- paste0('C:/Users/egrout/Dropbox/coatithon/processed/split_analysis_processed/',group,'_manual_split_merge_clean.csv')
#radii to use
R_inner <- 15
R_outer <- 50
#------TIME ZONE------
#set time zone to UTC to avoid confusing time zone issues
Sys.setenv(TZ='UTC')
#DIRECTORIES AND PARAMETERS
if(user %in% c('Ari','ari')){
codedir <- '~/Dropbox/code_ari/coatithon_code/'
dir <- '~/Dropbox/coati/processed/' #directory where all data is stored
if(group == 'galaxy'){
groupdir <- '~/Dropbox/coati/processed/galaxy/'
} else if(group=='presedente'){
groupdir <- '~/Dropbox/coati/processed/presedente/'
}
} else{
codedir <- 'C:/Users/egrout/Dropbox/coatithon/coatithon_code/'
if(group == 'galaxy'){
groupdir <- "C:/Users/egrout/Dropbox/coatithon/processed/2022/galaxy/"
} else if(group == 'presedente'){
groupdir <- "C:/Users/egrout/Dropbox/coatithon/processed/2023/presedente/"
}
}
#FUNCTIONS
#read in functions
setwd(codedir)
source('coati_function_library.R')
#LOAD DATA
#navigate into directory
setwd(groupdir)
#read in coati ids
load(file=paste0(group,'_coati_ids.RData'))
#modify coati ids to only include first 3 letters
coati_ids$name_short <- sapply(coati_ids$name, function(x){return(substr(x,1,3))})
#read in timestamp data
load(file=paste0(group,'_xy_highres_level1.RData'))
#PROCESS
setwd(codedir)
#read in events if using manual events
if(use_manual_events){
events <- read.csv(events.filename, sep=';')
} else{ #otherwise do it automatically
ff_data <- detect_fissions_and_fusions(R_inner = R_inner, R_outer = R_outer, xs, ys, ts, coati_ids)
events <- ff_data$events_detected
}
#CHARACTERIZE EVENTS
#preprocess events to...
if(use_manual_events){
events <- events[which(events$fission_time!='before start'),] #remove events where we missed the start
events <- events[which(events$event_type %in% c('fission','fusion')),] #only include fission and fusion events (remove 'almost fusion')
}
#create columns for subgroup idxs (initialize with zeros to convince R to let you do this)
events$group_A_idxs <- list(c(0,0,0))
events$group_B_idxs <- list(c(0,0,0))
for (i in 1:nrow(events)){
group_A_names <- events$group_A[i][[1]]
group_B_names <- events$group_B[i][[1]]
#if auto identified events, put in the right form (string) for matching
if(!use_manual_events){
group_A_names <- paste(group_A_names, collapse= ', ')
group_B_names <- paste(group_B_names, collapse= ', ')
}
group_A_idxs <- match_coati_names(group_A_names, coati_ids)
group_B_idxs <- match_coati_names(group_B_names, coati_ids)
events$group_A_idxs[i] <- list(group_A_idxs)
events$group_B_idxs[i] <- list(group_B_idxs)
}
#merge fission_time and fusion_time columns into one
if(use_manual_events){
events$time_min <- paste0(events$fission_time,events$fusion_time)
#convert to POSIX
events$datetime <- as.POSIXct(paste(events$date, events$time_min), format = "%Y-%m-%d %H:%M",tz = "UTC")
}
#match times to get indexes into matrices
events$tidx <- match(events$datetime, ts)
#count up how many individuals are in each group
events$n_A <- unlist(lapply(events$group_A_idxs,length))
events$n_B <- unlist(lapply(events$group_B_idxs,length))
events$before_time <- events$start_time <- events$end_time <- events$after_time <- NA
events$AB_before_disp <- events$A_during_disp <- events$B_during_disp <- NA
events$split_angle <- events$turn_angle_A <- events$turn_angle_B <- NA
for(i in c(1:nrow(events))){
print(i)
ff_data <- analyse_ff_event(i, events, xs, ys, ts, plot=F, max_time = 600)
if(!is.null(ff_data$disps)){
events$AB_before_disp[i] <- ff_data$disps['AB','before']
events$A_during_disp[i] <- ff_data$disps['A','during']
events$B_during_disp[i] <- ff_data$disps['B','during']
}
events$split_angle[i] <- ff_data$split_angle
events$turn_angle_A[i] <- ff_data$turn_angle_A
events$turn_angle_B[i] <- ff_data$turn_angle_B
events$before_time[i] <- ff_data$before_time
events$start_time[i] <- ff_data$start_time
events$end_time[i] <- ff_data$end_time
events$after_time[i] <- ff_data$after_time
}
#adding age class as a number in coati_ids
coati_ids$age_class <- NA
coati_ids$age_class[coati_ids$age == "Juvenile"] <- 1
coati_ids$age_class[coati_ids$age == "Sub-adult"] <- 2
coati_ids$age_class[coati_ids$age == "Adult"] <- 3
#this for loop is running through each groups IDs and assigning their age class and getting the groups average age
events$A_average_grp_age <- NA
events$A_age_each_ind <- events$group_A_idxs
events$B_average_grp_age <- NA
events$B_age_each_ind <- events$group_B_idxs
for (i in 1:nrow(events)){
if (group == "galaxy"){
v1 <- unlist(events$A_age_each_ind[i])
v1[v1 == 1] <- 1
v1[v1 == 2] <- 3
v1[v1 == 3] <- 3
v1[v1 == 4] <- 3
v1[v1 == 5] <- 3
v1[v1 == 6] <- 3
v1[v1 == 7] <- 2
v1[v1 == 8] <- 2
v1[v1 == 9] <- 2
v1[v1 == 10] <- 3
v1[v1 == 11] <- 3
events$A_average_grp_age[i] <- mean(v1)
events$A_n_adults[i] <- length(v1[v1=="3"])
events$A_n_subadults[i] <- length(v1[v1=="2"])
events$A_n_juveniles[i] <- length(v1[v1=="1"])
events$A_proportion_adults[i] <- length(v1[v1=="3"])/length(v1)
events$A_proportion_subadults[i] <- length(v1[v1=="2"])/length(v1)
events$A_proportion_juveniles[i] <- length(v1[v1=="1"])/length(v1)
events$A_subgroup_size[i] <- length(v1)
events$A_age_each_ind[i] <- relist((v1), skeleton=events$A_age_each_ind[i])
#for  group
v1 <- unlist(events$B_age_each_ind[i])
v1[v1 == 1] <- 1
v1[v1 == 2] <- 3
v1[v1 == 3] <- 3
v1[v1 == 4] <- 3
v1[v1 == 5] <- 3
v1[v1 == 6] <- 3
v1[v1 == 7] <- 2
v1[v1 == 8] <- 2
v1[v1 == 9] <- 2
v1[v1 == 10] <- 3
v1[v1 == 11] <- 3
events$B_average_grp_age[i] <- mean(v1)
events$B_n_adults[i] <- length(v1[v1=="3"])
events$B_n_subadults[i] <- length(v1[v1=="2"])
events$B_n_juveniles[i] <- length(v1[v1=="1"])
events$B_proportion_adults[i] <- length(v1[v1=="3"])/length(v1)
events$B_proportion_subadults[i] <- length(v1[v1=="2"])/length(v1)
events$B_proportion_juveniles[i] <- length(v1[v1=="1"])/length(v1)
events$B_subgroup_size[i] <- length(v1)
events$B_age_each_ind[i] <- relist((v1), skeleton=events$B_age_each_ind[i])
} else if (group == "presedente"){
v1 <- unlist(events$A_age_each_ind[i])
v1[v1 == 1] <- 3
v1[v1 == 2] <- 1
v1[v1 == 3] <- 1
v1[v1 == 4] <- 1
v1[v1 == 5] <- 3
v1[v1 == 6] <- 2
v1[v1 == 7] <- 2
v1[v1 == 8] <- 3
v1[v1 == 9] <- 3
v1[v1 == 10] <- 2
v1[v1 == 11] <- 1
v1[v1 == 12] <- 1
v1[v1 == 13] <- 3
v1[v1 == 14] <- 2
v1[v1 == 15] <- 1
v1[v1 == 16] <- 1
v1[v1 == 17] <- 2
v1[v1 == 18] <- 3
v1[v1 == 19] <- 2
v1[v1 == 20] <- 3
v1[v1 == 21] <- 3
v1[v1 == 22] <- 1
events$A_average_grp_age[i] <- mean(v1)
events$A_n_adults[i] <- length(v1[v1=="3"])
events$A_n_subadults[i] <- length(v1[v1=="2"])
events$A_n_juveniles[i] <- length(v1[v1=="1"])
events$A_proportion_adults[i] <- length(v1[v1=="3"])/length(v1)
events$A_proportion_subadults[i] <- length(v1[v1=="2"])/length(v1)
events$A_proportion_juveniles[i] <- length(v1[v1=="1"])/length(v1)
events$A_subgroup_size[i] <- length(v1)
events$A_age_each_ind[i] <- relist((v1), skeleton=events$A_age_each_ind[i])
#for  group
v1 <- unlist(events$B_age_each_ind[i])
v1[v1 == 1] <- 3
v1[v1 == 2] <- 1
v1[v1 == 3] <- 1
v1[v1 == 4] <- 1
v1[v1 == 5] <- 3
v1[v1 == 6] <- 2
v1[v1 == 7] <- 2
v1[v1 == 8] <- 3
v1[v1 == 9] <- 3
v1[v1 == 10] <- 2
v1[v1 == 11] <- 1
v1[v1 == 12] <- 1
v1[v1 == 13] <- 3
v1[v1 == 14] <- 2
v1[v1 == 15] <- 1
v1[v1 == 16] <- 1
v1[v1 == 17] <- 2
v1[v1 == 18] <- 3
v1[v1 == 19] <- 2
v1[v1 == 20] <- 3
v1[v1 == 21] <- 3
v1[v1 == 22] <- 1
events$B_average_grp_age[i] <- mean(v1)
events$B_n_adults[i] <- length(v1[v1=="3"])
events$B_n_subadults[i] <- length(v1[v1=="2"])
events$B_n_juveniles[i] <- length(v1[v1=="1"])
events$B_proportion_adults[i] <- length(v1[v1=="3"])/length(v1)
events$B_proportion_subadults[i] <- length(v1[v1=="2"])/length(v1)
events$B_proportion_juveniles[i] <- length(v1[v1=="1"])/length(v1)
events$B_subgroup_size[i] <- length(v1)
events$B_age_each_ind[i] <- relist((v1), skeleton=events$B_age_each_ind[i])
}else {print("fail")}
}
if(use_manual_events){
save(list = c('events'), file = paste0(groupdir, group,'_manual_ff_events_characterized.RData'))
} else{
save(list = c('events'), file = paste0(groupdir, group,'_auto_ff_events_characterized.RData'))
}
View(events)
#Check whether the before period overlaps with a preceding event involving some of the same individuals
events$ovlp_before <- events$ovlp_during <- events$ovlp_after <- list(c(0))
events$n_ovlp_before <- events$n_ovlp_during <- events$n_ovlp_after <- NA
for(i in 1:nrow(events)){
#before time and after time of the current event
before_time_curr <- events$before_time[i]
start_time_curr <- events$start_time[i]
end_time_curr <- events$end_time[i]
after_time_curr <- events$after_time[i]
#individuals
inds_in_event <- c(events$group_A_idxs[i][[1]], events$group_B_idxs[i][[1]])
#lists of overlapping events - set to empty lists initially
ovlp_before <- ovlp_during <- ovlp_after <- list()
#loop through other events to see if they overlap
for(j in 1:nrow(events)){
#skip the current event
if(i==j){
next
}
#if the events don't involve any of the same individuals, skip
inds_in_other_event <- c(events$group_A_idxs[j][[1]], events$group_B_idxs[j][[1]])
if(length(intersect(inds_in_event, inds_in_other_event))==0){
next
}
#get start and end time of the other event
start_time_other <- events$start_time[j]
end_time_other <- events$end_time[j]
#check if another event (start - end period) falls within before_time and start_time of the current event
if(!is.na(before_time_curr) & !is.na(start_time_curr) & !is.na(end_time_other) & !is.na(start_time_other)){
if(before_time_curr <= end_time_other & start_time_curr >= start_time_other){
ovlp_before <- c(ovlp_before, j)
}
}
#check if another event (start - end period) falls within start_time and end_time of the current event
if(!is.na(start_time_curr) & !is.na(end_time_curr) & !is.na(end_time_other) & !is.na(start_time_other)){
if(start_time_curr <= end_time_other & end_time_curr >= start_time_other){
ovlp_during <- c(ovlp_during, j)
}
}
#check if another event (start - end period) falls within end_time and after_time of the current event
if(!is.na(end_time_curr) & !is.na(after_time_curr) & !is.na(end_time_other) & !is.na(start_time_other)){
if(end_time_curr <= end_time_other & after_time_curr >= start_time_other){
ovlp_after <- c(ovlp_after, j)
}
}
}
events$ovlp_before[i] <- list(ovlp_before)
events$ovlp_during[i] <- list(ovlp_during)
events$ovlp_after[i] <- list(ovlp_after)
}
events$n_ovlp_before <- sapply(events$ovlp_before, length)
events$n_ovlp_during <- sapply(events$ovlp_during, length)
events$n_ovlp_after <- sapply(events$ovlp_after, length)
events$n_ovlp_before
